{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc63fb4-6ef3-48a4-bfef-c8b068c727f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a3c029-d3ca-4e72-93c8-60814c3a196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:03<00:00,  3.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "name = \"bigcode/starcoder2-15b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.bfloat16).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66926b55-c76b-459f-a102-810e621b9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "lang = \"racket\"\n",
    "multiplt = datasets.load_dataset(\"nuprl/MultiPL-T\", split=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e6435f-44ac-4257-8e3a-2d91e6bda7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";; Return the length of a base directory path, including the last '/'.\n",
      "(define (base_dir_length base_dir_path)\n",
      "\t(if (equal? (string-ref base_dir_path (- (string-length base_dir_path) 1)) #\\/)\n",
      "\t\t(string-length base_dir_path)\n",
      "\t\t(+ (string-length base_dir_path) 1)))\n"
     ]
    }
   ],
   "source": [
    "# just a random func\n",
    "import random\n",
    "fn = random.choice(multiplt[\"content\"])\n",
    "print(fn)\n",
    "entrypoint = fn.split(\"(define (\")[1].split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0e0d0-a8ce-4ec8-a59f-644dc3dfff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"<issue_start>username_0: You are exceptionally skilled at crafting high-quality programming problems and\n",
    "offering precise solutions.\n",
    "Please gain inspiration from the following random code snippet to create a\n",
    "high-quality programming problem in {lang.title()}. Present your output in two distinct sections:\n",
    "[Problem Description] and [Solution].\n",
    "\n",
    "Code snippet for inspiration:\n",
    "```{lang}\n",
    "{fn}\n",
    "```\n",
    "Guidelines for each section:\n",
    "1. [Problem Description]: This should be **completely self-contained**, providing\n",
    "all the contextual information one needs to understand and solve the problem.\n",
    "Assume common programming knowledge, but ensure that any specific context,\n",
    "variables, or code snippets pertinent to this problem are explicitly included.\n",
    "2. [Solution]: Offer a comprehensive, **correct** solution that accurately\n",
    "addresses the [Problem Description] you provided.<issue_comment>username_1: Sure, no problem. I will be able to help. I am  exceptionally skilled at crafting high-quality programming problems and\n",
    "offering precise solutions.\n",
    "I will use your provided code snippet for {entrypoint} as inspiration for the problem.\n",
    "\n",
    "# [Problem Description]\n",
    "\"\"\"\n",
    "\n",
    "toks = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "gen = model.generate(toks, max_new_tokens=700, do_sample=True, temperature=0.4, top_p=0.9)[0]\n",
    "dec = tokenizer.decode(gen[len(toks[0]):])\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca737ad-d0c3-4ba5-8827-6e7e284f5836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
