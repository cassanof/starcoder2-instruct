{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8cdfa1-aad1-42a2-9f45-92b93a97c036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/federicoc/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d61f1-89c1-4895-831b-d178938227da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "name = \"bigcode/starcoder2-15b_16k\"\n",
    "model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.bfloat16).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e26cf3-91ed-486b-b47c-124a332904ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(ins, code, title=\"Changes to exercise1\"):\n",
    "    header = f\"\"\"<pr>Title: {title}\n",
    "username_0: This PR resolves the following request.\n",
    "{ins}<pr_status>opened<repo_name>code-editing/python-exercises<pr_base><pr_file>/problems/exercise1.py<pr_base_code>\"\"\"\n",
    "    base_code = f\"\"\"<pr_base_code>{code}<pr_diff><pr_file>/problems/exercise1.py<pr_diff_hunk>\"\"\"\n",
    "    prompt = header + base_code\n",
    "    return prompt\n",
    "\n",
    "code = \"\"\"def add(x, y):\n",
    "    return x + y\"\"\"\n",
    "\n",
    "prompt = make_prompt(\"Add a function called `substract` that subtracts two numbers\", code)\n",
    "toks = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7efd309-a5f9-4291-acc2-7f1893a6c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.49k/2.49k [00:00<00:00, 21.0MB/s]\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136k/136k [00:00<00:00, 483kB/s]\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 2626.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.load_dataset(\"nuprl/CanItEdit\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ceb740b-5f7a-418f-9532-ab40c23b1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43 is two hunks\n",
    "ex = ds[22]\n",
    "before = ex[\"before\"]\n",
    "ins = ex[\"instruction_descriptive\"]\n",
    "prompt = make_prompt(ins, before)\n",
    "toks = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96836cdb-1327-4e72-af0c-f8b0eea9131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/federicoc/.env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:411: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/scratch/federicoc/.env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:416: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2181\n",
      "1\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "outs = model.generate(toks, max_new_tokens=2000, temperature=0, top_p=0.95, do_sample=False)[0]\n",
    "print(len(outs))\n",
    "print(len(toks))\n",
    "outs = outs[len(toks[0]):]\n",
    "print(len(outs))\n",
    "dec = tokenizer.decode(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbabe780-8991-4068-a52a-07829b80ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_end_toks = [\n",
    "    \"<pr_review>\", \"<pr_comment>\", \"<pr>\", \"<pr_review_comment>\"\n",
    "]\n",
    "# <pr_review>, <pr_comment>, <pr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc06d06-4c8e-448f-b9f2-261875051569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -1,9 +1,18 @@\n",
      " import numpy as np\n",
      " \n",
      " class MarkovChain:\n",
      " \n",
      "     def create_transition_matrix(self, matrix):\n",
      "         \n",
      "         matrix = np.array(matrix)\n",
      "         column_sums = np.sum(matrix, axis=0)\n",
      "         normalized_matrix = matrix / column_sums\n",
      "-        return normalized_matrix.tolist()\n",
      "+        return normalized_matrix.tolist() \n",
      "+\n",
      "+    def translate_from_list(self, adj_list: Dict[int, List[int]]) -> List[List[float]]:\n",
      "+        matrix = np.zeros((len(adj_list), len(adj_list)))\n",
      "+        for i in adj_list:\n",
      "+            for j in adj_list[i]:\n",
      "+                matrix[i][j] = 1\n",
      "+        column_sums = np.sum(matrix, axis=0)\n",
      "+        normalized_matrix = matrix / column_sums\n",
      "+        return normalized_matrix.tolist()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tok in pr_end_toks:\n",
    "    found = dec.find(tok)\n",
    "    if found != -1:\n",
    "        dec = dec[:found]\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a387c6-4015-4f88-9ca2-d186d665fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hunks = dec.split(\"<pr_diff_hunk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e2d6b9-990b-4d74-bea0-55027246143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -1,9 +1,18 @@\n",
      " import numpy as np\n",
      " \n",
      " class MarkovChain:\n",
      " \n",
      "     def create_transition_matrix(self, matrix):\n",
      "         \n",
      "         matrix = np.array(matrix)\n",
      "         column_sums = np.sum(matrix, axis=0)\n",
      "         normalized_matrix = matrix / column_sums\n",
      "-        return normalized_matrix.tolist()\n",
      "+        return normalized_matrix.tolist() \n",
      "+\n",
      "+    def translate_from_list(self, adj_list: Dict[int, List[int]]) -> List[List[float]]:\n",
      "+        matrix = np.zeros((len(adj_list), len(adj_list)))\n",
      "+        for i in adj_list:\n",
      "+            for j in adj_list[i]:\n",
      "+                matrix[i][j] = 1\n",
      "+        column_sums = np.sum(matrix, axis=0)\n",
      "+        normalized_matrix = matrix / column_sums\n",
      "+        return normalized_matrix.tolist()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hunk in hunks:\n",
    "    print(hunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "756d17ee-5b3c-458f-8a78-250f78365b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "class MarkovChain:\n",
      "\n",
      "    def create_transition_matrix(self, matrix):\n",
      "        \n",
      "        matrix = np.array(matrix)\n",
      "        column_sums = np.sum(matrix, axis=0)\n",
      "        normalized_matrix = matrix / column_sums\n",
      "        return normalized_matrix.tolist()\n"
     ]
    }
   ],
   "source": [
    "print(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660564a1-3d3a-46e1-bca5-ab89abdad43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"<issue_start>username_0: I have a program in Python that I'd like to change.\n",
    "\n",
    "Here is the code for the program:\n",
    "```py\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "Add a \"sub\" function that subtracts two numbers. Also write docstrings for both functions and change a,b to x,y.\n",
    "\n",
    "Please someone help me. Can you also provide the full code with the change?<issue_comment>username_1: Sure, no problem. I will be able to help. I am an expert in editing Python code.\n",
    "\n",
    "Here is the full code with the change:\n",
    "```py\n",
    "def add(x, y):\n",
    "    \\\"\\\"\\\"Adds two numbers.\\\"\\\"\\\"\n",
    "    return x + y\n",
    "\n",
    "    def sub(x, y):\n",
    "    \\\"\\\"\\\"Subtracts two numbers.\\\"\\\"\\\"\n",
    "    return x - y\n",
    "```\n",
    "Upvotes: 200<issue_comment>username_0: Thank you so much! I have another program in Python that I'd like to change.\n",
    "\n",
    "Here is the code for the program:\n",
    "```py\n",
    "{before}\n",
    "```\n",
    "\n",
    "{ins}\n",
    "\n",
    "Please someone help me. Can you also provide the full code with the change?\n",
    "Upvotes: 100<issue_comment>username_1: Sure, no problem. I will be able to help. I am an expert in editing Python code.\n",
    "\n",
    "Here is the full code with the change:\n",
    "```py\"\"\"\n",
    "\n",
    "toks = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "gen = model.generate(toks, max_new_tokens=1200)[0]\n",
    "dec = tokenizer.decode(gen[len(toks[0]):])\n",
    "print(dec.split(\"```\")[0])\n",
    "# print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf80860-9d80-44c0-a1ba-29704845056d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
